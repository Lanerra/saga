# config.py
"""
Configuration settings for the Saga Novel Generation system.
Centralizes constants for API endpoints, model names, file paths,
generation parameters, validation thresholds, and logging settings.
"""

import os
import numpy as np
import logging # Import logging to use its constants like INFO
from typing import Optional

# --- API and Model Configuration ---
# URL for the Ollama server providing embeddings
OLLAMA_EMBED_URL: str = "http://192.168.64.1:11434"
# Base URL for the OpenAI-compatible API endpoint
OPENAI_API_BASE: str = "http://192.168.64.1:8080/v1"
# API Key for the OpenAI-compatible endpoint (replace if necessary)
OPENAI_API_KEY: str = "nope"

# Name of the embedding model used via Ollama
EMBEDDING_MODEL: str = "nomic-embed-text:latest"
# Name of the main large language model for text generation
MAIN_GENERATION_MODEL: str = "Qwen3-30B-A3B"

# --- Output and File Paths ---
# Directory to store all output files (database, JSON state, chapter texts)
OUTPUT_DIR: str = "novel_output"
# Path to the SQLite database file
DATABASE_FILE: str = os.path.join(OUTPUT_DIR, "novel_data.db")
# Path to the JSON file storing the plot outline
PLOT_OUTLINE_FILE: str = os.path.join(OUTPUT_DIR, "plot_outline.json")
# Path to the JSON file storing character profiles
CHARACTER_PROFILES_FILE: str = os.path.join(OUTPUT_DIR, "character_profiles.json")
# Path to the JSON file storing world-building information
WORLD_BUILDER_FILE: str = os.path.join(OUTPUT_DIR, "world_building.json")

# Ensure the main output directory exists upon script load
os.makedirs(OUTPUT_DIR, exist_ok=True)

# --- Generation Parameters ---
# Maximum number of characters to include in the context prompt for the LLM
MAX_CONTEXT_LENGTH: int = 30000
# Default maximum number of tokens the LLM should generate in a response
MAX_GENERATION_TOKENS: int = 15000 # Increased as per original code
# Maximum number of characters from a chapter to use for knowledge update prompts (character/world analysis)
KNOWLEDGE_UPDATE_SNIPPET_SIZE: int = 8000
# Number of most relevant past chapters to retrieve for semantic context generation
CONTEXT_CHAPTER_COUNT: int = 5
# Number of chapters to attempt writing in a single execution run
CHAPTERS_PER_RUN: int = 3


# --- NEW: Agentic Planning ---
ENABLE_AGENTIC_PLANNING: bool = True # Flag to enable the new planning step
MAX_PLANNING_TOKENS: int = 8000 # Max tokens for the planning LLM call

# --- Revision and Validation ---
# Cosine similarity threshold below which chapter coherence triggers revision
REVISION_COHERENCE_THRESHOLD: float = 0.65
# Flag to enable triggering revisions based on consistency check failures
REVISION_CONSISTENCY_TRIGGER: bool = True
# Flag to enable triggering revisions based on plot arc validation failures
PLOT_ARC_VALIDATION_TRIGGER: bool = True
# Similarity threshold for revision check (revisions less similar than this are accepted)
REVISION_SIMILARITY_ACCEPTANCE: float = 0.98 # Revisions scoring >= this are rejected as too similar

# --- NEW: Draft Evaluation ---
MIN_ACCEPTABLE_DRAFT_LENGTH: int = 1500 # Minimum character length for a generated draft to be considered valid

# --- NEW: Dynamic State Adaptation ---
ENABLE_DYNAMIC_STATE_ADAPTATION: bool = True # Allow LLM to propose modifications to profiles/world

# --- Embedding Configuration ---
# Expected dimension of the embeddings generated by EMBEDDING_MODEL
EXPECTED_EMBEDDING_DIM: int = 768
# NumPy data type to use for storing and processing embeddings
EMBEDDING_DTYPE: np.dtype = np.float32
# Maximum number of embedding results to cache in memory (using LRU cache)
EMBEDDING_CACHE_SIZE: int = 128

# --- Logging ---
# Logging level for the application (e.g., "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL")
LOG_LEVEL: str = "INFO"
# Format string for log messages
LOG_FORMAT: str = '%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s'
# Path for optional log file (set to None to disable file logging)
LOG_FILE: Optional[str] = os.path.join(OUTPUT_DIR, "saga_run.log")

# --- Default Generation Settings (used if files are missing) ---
# Default genre if plot outline is generated
DEFAULT_GENRE: str = "hard science fiction"
# Default theme if plot outline is generated
DEFAULT_THEME: str = "the nature of consciousness and isolation"
# Default protagonist description if plot outline is generated
DEFAULT_PROTAGONIST: str = "A newly self-aware deep-space maintenance AI discovering its solitary existence after its human crew vanished centuries ago."

