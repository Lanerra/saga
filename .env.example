      
# .env
# API and Model Configuration
OLLAMA_EMBED_URL=http://127.0.0.1:11434
OPENAI_API_BASE=http://127.0.0.1:8080/v1
OPENAI_API_KEY=nope
EMBEDDING_MODEL=nomic-embed-text:latest

# Neo4j Connection Settings
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=saga_password
NEO4J_DATABASE=neo4j

# Model Aliases
LARGE_MODEL=Qwen3-14B-Q4
MEDIUM_MODEL=Qwen3-8B-Q4
SMALL_MODEL=Qwen3-4B-Q4
NARRATOR_MODEL=Qwen3-14B-Q4

# --- SAGA Generation Parameters ---

# Novel Configuration
# Enable unhinged plot mode (True/False)
UNHINGED_PLOT_MODE=False

# Generation Run Settings
# Number of chapters to generate per run
CHAPTERS_PER_RUN=3

# Scene Planning (Agentic Planning)
# Minimum number of scenes to target per chapter plan
TARGET_SCENES_MIN=3
# Maximum number of scenes to target per chapter plan
TARGET_SCENES_MAX=7

# Token Limits
# Maximum context tokens for LLM calls
MAX_CONTEXT_TOKENS=40960
# Maximum tokens for LLM generation
MAX_GENERATION_TOKENS=16384
# Maximum tokens for summary generation
MAX_SUMMARY_TOKENS=4096
# Maximum tokens for knowledge graph triple extraction
MAX_KG_TRIPLE_TOKENS=8192
# Maximum tokens for knowledge graph pre-population
MAX_PREPOP_KG_TOKENS=16384
# Maximum tokens for planning phase
MAX_PLANNING_TOKENS=8192

# Draft Quality & Length
# Minimum acceptable character length for a draft chapter.
# WARNING: Setting this significantly higher than 13000 (e.g., 15000+)
# can lead to AI generating excessively long chapters (30,000+ characters)
# as it tries to meet the length requirement, potentially sacrificing quality or coherence.
MIN_ACCEPTABLE_DRAFT_LENGTH=13000

# Revision Process
# Enable patch-based revision system (True/False)
ENABLE_PATCH_BASED_REVISION=True
# Maximum number of patch instructions to generate per revision cycle
MAX_PATCH_INSTRUCTIONS_TO_GENERATE=3
# Coherence threshold for revision (e.g., 0.60)
REVISION_COHERENCE_THRESHOLD=0.60
# Similarity acceptance threshold (if patched text is this similar to original, log warning)
REVISION_SIMILARITY_ACCEPTANCE=0.985

# LLM Call Robustness
# Number of retry attempts for LLM calls
LLM_RETRY_ATTEMPTS=3

# --- Logging ---
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO # Example if you want to override default INFO

# --- Rich Progress Display ---
# Enable Rich progress display (True/False)
ENABLE_RICH_PROGRESS=True # Example