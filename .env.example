# .env
# API and Model Configuration
EMBEDDING_API_BASE=http://127.0.0.1:11434
EMBEDDING_API_KEY=nope
OPENAI_API_BASE=http://127.0.0.1:8080/v1
OPENAI_API_KEY=nope
EMBEDDING_MODEL="nomic-embed-text:latest"
EXPECTED_EMBEDDING_DIM=768
ENABLE_RERANKING=True

# Neo4j Connection Settings
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=saga_password
NEO4J_DATABASE=neo4j
NEO4J_VECTOR_DIMENSIONS=768

# Model Aliases
LARGE_MODEL="qwen3-a3b"
MEDIUM_MODEL="qwen3-a3b"
SMALL_MODEL="qwen3-a3b"
NARRATIVE_MODEL="qwen3-a3b"

# --- Novel Configuration ---
CONFIGURED_GENRE="science fiction"
CONFIGURED_THEME="the tension between progress and preservation"
CONFIGURED_SETTING_DESCRIPTION="a frontier town on the edge of unexplored alien wilderness"
DEFAULT_PROTAGONIST_NAME="Winifred"
DEFAULT_PLOT_OUTLINE_TITLE= "Further Out"

# --- SAGA Generation Parameters ---
# Toggle for the "/no_think" directive in LLM prompts.
ENABLE_LLM_NO_THINK_DIRECTIVE=True

# Novel Configuration
# Generation Run Settings
# Number of total plot points in the whole narrative
TARGET_PLOT_POINTS_INITIAL_GENERATION=18

# Maximum chapters to generate per run; loop stops early if no plot points remain
CHAPTERS_PER_RUN=6

# Scene Planning (Agentic Planning)
# Minimum number of scenes to target per chapter plan
TARGET_SCENES_MIN=4
# Maximum number of scenes to target per chapter plan
TARGET_SCENES_MAX=6

# Token Limits
# Maximum context tokens for LLM calls
MAX_CONTEXT_TOKENS=40960

# LLM Call Robustness
# Number of retry attempts for LLM calls
LLM_RETRY_ATTEMPTS=3

# --- Logging ---
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO # Example if you want to override default INFO

# --- Rich Progress Display ---
# Enable Rich progress display (True/False)
ENABLE_RICH_PROGRESS=True # Example
